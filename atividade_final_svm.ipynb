{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1j-iirnjAnR_w7vmQzuPrBa-hWUBi0vzX",
      "authorship_tag": "ABX9TyPJ9tpHb1iGaxwbGZe6eTzo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Diego251Fagundes/Data-Science-Machine-Learning-Studies/blob/main/atividade_final_svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Descri√ß√£o do Dataset**\n",
        "O presente dataset representa o perfil de microbiota intestinal de crian√ßas com e sem Transtorno do Espectro Autista (ASD). Ele foi constru√≠do a partir de sequenciamento de 16S rRNA, gerando uma matriz de abund√¢ncia categorizada de microrganismos.\n",
        "\n",
        "Amostras: 61 crian√ßas\n",
        "\n",
        "Grupo A ‚Üí Crian√ßas com ASD (Autistic Spectrum Disorder)\n",
        "\n",
        "Grupo B ‚Üí Crian√ßas com desenvolvimento t√≠pico (TD ‚Äì Typically Developing)\n",
        "\n",
        "Vari√°veis: 5619 microrganismos identificados em n√≠vel taxon√¥mico (g√™nero e esp√©cie), com nomes no formato padr√£o:\n",
        "\n",
        "Exemplo: g__Faecalibacterium;s__Faecalibacterium prausnitzii\n",
        "\n",
        "Natureza dos dados:\n",
        "\n",
        "Cada c√©lula da matriz indica a categoria de abund√¢ncia relativa de um microrganismo em uma amostra.\n",
        "\n",
        "Os valores s√£o representados qualitativamente como low (baixa abund√¢ncia), mid (abund√¢ncia intermedi√°ria), high (alta abund√¢ncia), al√©m de casos espec√≠ficos de absent (ausente) e present (presente).\n",
        "\n",
        "Assim, o dataset reflete a composi√ß√£o microbiana intestinal de cada crian√ßa, permitindo investigar se h√° padr√µes que distinguem crian√ßas com ASD das crian√ßas com desenvolvimento t√≠pico.\n",
        "\n",
        "üß© Hip√≥tese\n",
        "A composi√ß√£o da microbiota intestinal difere significativamente entre crian√ßas com Transtorno do Espectro Autista (ASD) e com desenvolvimento t√≠pico (TD), e tais diferen√ßas podem ser detectadas e exploradas por m√©todos de aprendizado de m√°quina, como SVM, para discriminar os grupos com base no perfil microbiano.\n",
        "\n",
        "‚ùì Quest√£o norteadora\n",
        "√â poss√≠vel identificar padr√µes na microbiota intestinal que discriminem crian√ßas com ASD de crian√ßas com desenvolvimento t√≠pico (TD) utilizando algoritmos de aprendizado de m√°quina, e como os diferentes m√©todos de busca de hiperpar√¢metros (GridSearchCV e RandomizedSearchCV) influenciam a performance dessa classifica√ß√£o?\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "EqKAXgWOuISy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Explora√ß√£o do Dataset**\n",
        "\n",
        "Leia e descreva a composi√ß√£o do dataset (amostras, grupos e vari√°veis).\n",
        "Reflita sobre o que significa cada categoria de abund√¢ncia (low, mid, high, absent, present)."
      ],
      "metadata": {
        "id": "9pOcGbSWwOb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# L√™ o arquivo csv\n",
        "df = pd.read_csv('ASD_meta_abundance_discretized.csv')\n",
        "# Exibe as 5 primeiras linhas\n",
        "print(df.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZbpTqRySuKA5",
        "outputId": "774e6351-8ead-4e5e-c6d4-5491c7addf57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Unnamed: 0 g__Faecalibacterium;s__Faecalibacterium prausnitzii  \\\n",
            "0         A3                                                mid    \n",
            "1         A5                                                mid    \n",
            "2         A6                                                low    \n",
            "3         A9                                                mid    \n",
            "4        A31                                                mid    \n",
            "\n",
            "  g__Hungatella;s__Hungatella hathewayi  \\\n",
            "0                                  high   \n",
            "1                                  high   \n",
            "2                                   mid   \n",
            "3                                   low   \n",
            "4                                   low   \n",
            "\n",
            "  g__Clostridium;s__uncultured Clostridium sp.  \\\n",
            "0                                          mid   \n",
            "1                                          low   \n",
            "2                                          low   \n",
            "3                                         high   \n",
            "4                                         high   \n",
            "\n",
            "  g__Butyricimonas;s__Butyricimonas virosa  \\\n",
            "0                                      low   \n",
            "1                                      mid   \n",
            "2                                      low   \n",
            "3                                      mid   \n",
            "4                                      low   \n",
            "\n",
            "  g__Alistipes;s__Alistipes indistinctus  \\\n",
            "0                                    low   \n",
            "1                                    low   \n",
            "2                                    low   \n",
            "3                                    low   \n",
            "4                                   high   \n",
            "\n",
            "  g__Unclassified;s__Firmicutes bacterium CAG:176  \\\n",
            "0                                             low   \n",
            "1                                             low   \n",
            "2                                             low   \n",
            "3                                             mid   \n",
            "4                                             low   \n",
            "\n",
            "  g__Clostridium;s__Clostridium sp. CAG:7  \\\n",
            "0                                    high   \n",
            "1                                     mid   \n",
            "2                                     mid   \n",
            "3                                    high   \n",
            "4                                     mid   \n",
            "\n",
            "  g__Unclassified;s__Firmicutes bacterium CAG:882  \\\n",
            "0                                             low   \n",
            "1                                             low   \n",
            "2                                             low   \n",
            "3                                             low   \n",
            "4                                             low   \n",
            "\n",
            "  g__Lachnoclostridium;s__[Clostridium] asparagiforme  ...  \\\n",
            "0                                                low   ...   \n",
            "1                                                low   ...   \n",
            "2                                               high   ...   \n",
            "3                                                low   ...   \n",
            "4                                                low   ...   \n",
            "\n",
            "  g__Unclassified;s__Clostridium phage c-st  \\\n",
            "0                                    absent   \n",
            "1                                    absent   \n",
            "2                                    absent   \n",
            "3                                    absent   \n",
            "4                                    absent   \n",
            "\n",
            "  g__Unclassified;s__Enterococcus phage EFDG1  \\\n",
            "0                                      absent   \n",
            "1                                      absent   \n",
            "2                                      absent   \n",
            "3                                      absent   \n",
            "4                                      absent   \n",
            "\n",
            "  g__Unclassified;s__Podovirus Lau218 g__Sap6virus;s__Enterococcus phage VD13  \\\n",
            "0                              absent                                  absent   \n",
            "1                              absent                                  absent   \n",
            "2                              absent                                  absent   \n",
            "3                              absent                                  absent   \n",
            "4                              absent                                  absent   \n",
            "\n",
            "  g__Unclassified;s__Bacillus phage vB_BanS-Tsamsa  \\\n",
            "0                                           absent   \n",
            "1                                           absent   \n",
            "2                                           absent   \n",
            "3                                           absent   \n",
            "4                                           absent   \n",
            "\n",
            "  g__Unclassified;s__Gordonia phage GTE2  \\\n",
            "0                                 absent   \n",
            "1                                 absent   \n",
            "2                                 absent   \n",
            "3                                 absent   \n",
            "4                                 absent   \n",
            "\n",
            "  g__Alphabaculovirus;s__Hyphantria cunea nucleopolyhedrovirus  \\\n",
            "0                                             absent             \n",
            "1                                             absent             \n",
            "2                                             absent             \n",
            "3                                             absent             \n",
            "4                                             absent             \n",
            "\n",
            "  g__Potyvirus;s__Bean common mosaic virus  \\\n",
            "0                                   absent   \n",
            "1                                   absent   \n",
            "2                                   absent   \n",
            "3                                   absent   \n",
            "4                                   absent   \n",
            "\n",
            "  g__Potyvirus;s__Telosma mosaic virus  \\\n",
            "0                               absent   \n",
            "1                               absent   \n",
            "2                               absent   \n",
            "3                               absent   \n",
            "4                               absent   \n",
            "\n",
            "  g__Unclassified;s__Freshwater phage uvFW-CGR-AMD-COM-C203  \n",
            "0                                             absent         \n",
            "1                                             absent         \n",
            "2                                             absent         \n",
            "3                                             absent         \n",
            "4                                             absent         \n",
            "\n",
            "[5 rows x 5620 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "604af383"
      },
      "source": [
        "A estrutura do Dataset √© composta por:\n",
        "\n",
        "*   **Amostras:** O conjunto de dados cont√©m um total de 61 amostras. Cada amostra representa o perfil da microbiota intestinal de uma crian√ßa.\n",
        "\n",
        "*   **Grupos:** As amostras est√£o divididas em dois grupos distintos, conforme identificado pela primeira letra do identificador de cada amostra:\n",
        "    *   Grupo A (ASD): Formado por 30 crian√ßas diagnosticadas com Transtorno do Espectro Autista.\n",
        "    *   Grupo B (TD): Formado por 31 crian√ßas com desenvolvimento t√≠pico (Typically Developing).\n",
        "\n",
        "*   **Vari√°veis:** O dataset possui 5619 vari√°veis. Cada vari√°vel corresponde a um microrganismo espec√≠fico, identificado em n√≠vel de g√™nero e esp√©cie (por exemplo, g__Faecalibacterium;s__Faecalibacterium prausnitzii).\n",
        "\n",
        "A matriz de dados utiliza uma abordagem qualitativa para representar a quantidade de cada microrganismo. Em vez de valores num√©ricos, s√£o usadas categorias textuais. O significado de cada uma √©:\n",
        "\n",
        "*   **high (alta):** Indica que o microrganismo foi encontrado em alta abund√¢ncia relativa naquela amostra.\n",
        "*   **mid (intermedi√°ria):** O microrganismo est√° presente em uma abund√¢ncia relativa intermedi√°ria.\n",
        "*   **low (baixa):** O microrganismo foi detectado, mas em baixa abund√¢ncia relativa.\n",
        "*   **present (presente):** Uma categoria mais gen√©rica que confirma a detec√ß√£o do microrganismo na amostra, mas sem especificar o n√≠vel de sua abund√¢ncia.\n",
        "*   **absent (ausente):** O microrganismo n√£o foi detectado naquela amostra espec√≠fica.\n",
        "\n",
        "Essa discretiza√ß√£o dos dados transforma contagens num√©ricas complexas em categorias mais simples e interpret√°veis, facilitando a compara√ß√£o de padr√µes gerais na composi√ß√£o da microbiota entre os grupos ASD e TD."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Experimento com GridSearchCV**\n",
        "Utilize o m√©todo GridSearchCV, que faz uma busca exaustiva em todas as combina√ß√µes de par√¢metros.\n",
        "\n",
        "**Reduzir o n√∫mero de vari√°veis (Use.: k=500 ou k=100 com SelectKBest)**.\n",
        "Observe quais par√¢metros foram escolhidos como √≥timos e qual foi o desempenho do modelo (acur√°cia, sensibilidade, especificidade, ROC-AUC).\n",
        "\n",
        "Reflita: quais s√£o as vantagens de testar todas as combina√ß√µes poss√≠veis? Quais s√£o as limita√ß√µes desse m√©todo?"
      ],
      "metadata": {
        "id": "-jL7_F3e9kIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bibliotecas necess√°rias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "#L√™ o arquivo csv\n",
        "df = pd.read_csv('ASD_meta_abundance_discretized.csv')\n",
        "\n",
        "# Renomeia a primeira coluna\n",
        "df = df.rename(columns={df.columns[0]: 'SampleID'})\n",
        "\n",
        "# Separa as features (X) e a vari√°vel-alvo (y)\n",
        "X = df.drop(columns=['SampleID'])\n",
        "y = df['SampleID'].apply(lambda x: 1 if 'A' in x else 0) # 1 para ASD, 0 para TD\n",
        "\n",
        "# Mapeia as categorias de abund√¢ncia para n√∫meros\n",
        "abundance_mapping = {\n",
        "    'absent': 0,\n",
        "    'present': 1,\n",
        "    'low': 2,\n",
        "    'mid': 3,\n",
        "    'high': 4\n",
        "}\n",
        "# Aplica o mapeamento a todas as colunas de microrganismos\n",
        "X_encoded = X.apply(lambda col: col.map(abundance_mapping)).fillna(0)\n",
        "\n",
        "# Divide os dados: 80% para treino, 20% para teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "# Reduz o n√∫mero de features para as 500 mais relevantes\n",
        "k_features = 500\n",
        "selector = SelectKBest(score_func=chi2, k=k_features)\n",
        "\n",
        "# Aplica o seletor aos dados de treino e teste\n",
        "X_train_kbest = selector.fit_transform(X_train, y_train)\n",
        "X_test_kbest = selector.transform(X_test)\n",
        "\n",
        "print(f\"N√∫mero de features original: {X_encoded.shape[1]}\")\n",
        "print(f\"N√∫mero de features reduzido: {X_train_kbest.shape[1]}\\n\")\n",
        "\n",
        "\n",
        "# Define o modelo a ser otimizado\n",
        "svc_model = SVC(probability=True, random_state=42)\n",
        "\n",
        "# Define o \"grid\" de hiperpar√¢metros para testar\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Configura e instancia o GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=svc_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "print(\"Iniciando a busca exaustiva com GridSearchCV...\")\n",
        "# Executa a busca nos dados de treino\n",
        "grid_search.fit(X_train_kbest, y_train)\n",
        "print(\"Busca com GridSearchCV finalizada.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Resultados do GridSearchCV ---\")\n",
        "print(f\"Melhores Par√¢metros Encontrados: {grid_search.best_params_}\")\n",
        "print(f\"Melhor Acur√°cia (valida√ß√£o cruzada): {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# melhor modelo encontrado\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "\n",
        "# Faz as previs√µes no conjunto de teste\n",
        "y_pred = best_svm_model.predict(X_test_kbest)\n",
        "y_pred_proba = best_svm_model.predict_proba(X_test_kbest)[:, 1]\n",
        "\n",
        "# Calcula a matriz de confus√£o\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "# Calcula as m√©tricas de desempenho\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(\"\\n--- Desempenho do Melhor Modelo no Conjunto de Teste ---\")\n",
        "print(f\"Acur√°cia: {accuracy:.4f}\")\n",
        "print(f\"Sensibilidade (Recall): {sensitivity:.4f}\")\n",
        "print(f\"Especificidade: {specificity:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LWG-2Z49uQx",
        "outputId": "afcf84f4-0c7a-4e93-9cb3-148a5a5e5dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de features original: 5619\n",
            "N√∫mero de features reduzido: 500\n",
            "\n",
            "Iniciando a busca exaustiva com GridSearchCV...\n",
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "Busca com GridSearchCV finalizada.\n",
            "\n",
            "--- Resultados do GridSearchCV ---\n",
            "Melhores Par√¢metros Encontrados: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Melhor Acur√°cia (valida√ß√£o cruzada): 0.9800\n",
            "\n",
            "--- Desempenho do Melhor Modelo no Conjunto de Teste ---\n",
            "Acur√°cia: 0.8333\n",
            "Sensibilidade (Recall): 0.8333\n",
            "Especificidade: 0.8333\n",
            "ROC-AUC: 0.9444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A principal **vantagem** de testar todas as combina√ß√µes poss√≠veis, √© a garantia de encontrar a melhor combina√ß√£o de par√¢metros dentro do \"grid\" que foi especificado. √â um m√©todo sistem√°tico e exaustivo, o que o torna muito confi√°vel para otimizar o desempenho do modelo, eliminando a necessidade de adivinha√ß√£o manual dos melhores valores.\n",
        "\n",
        "A maior **limita√ß√£o** desse m√©todo √© o seu alto custo computacional e o tempo de execu√ß√£o. Como o n√∫mero de modelos a serem treinados √© o produto do n√∫mero de valores para cada par√¢metro (ex: 3 valores para C * 2 para kernel * 2 para gamma = 12 combina√ß√µes), a busca pode se tornar extremamente lenta se o espa√ßo de busca for grande. Al√©m disso, ele s√≥ avalia os pontos discretos fornecidos no grid, e o verdadeiro valor √≥timo poderia estar em um ponto intermedi√°rio n√£o testado."
      ],
      "metadata": {
        "id": "RnrvtP1pEgbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Experimento com RandomizedSearchCV**\n",
        "Utilize o m√©todo RandomizedSearchCV, que faz uma busca aleat√≥ria em parte do espa√ßo de par√¢metros.\n",
        "\n",
        "Compare os resultados com os obtidos no GridSearchCV.\n",
        "\n",
        "Reflita: por que o RandomizedSearch pode encontrar resultados diferentes, √†s vezes melhores, √†s vezes piores, mesmo testando menos combina√ß√µes?"
      ],
      "metadata": {
        "id": "Py6MBCuEGt1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Importa√ß√£o das bibliotecas necess√°rias ---\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
        "import numpy as np\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# --- 1. Carregamento e Preparo dos Dados ---\n",
        "# (Esta parte √© id√™ntica √† do exerc√≠cio anterior)\n",
        "df = pd.read_csv('ASD_meta_abundance_discretized.csv')\n",
        "df = df.rename(columns={df.columns[0]: 'SampleID'})\n",
        "X = df.drop(columns=['SampleID'])\n",
        "y = df['SampleID'].apply(lambda x: 1 if 'A' in x else 0)\n",
        "\n",
        "# --- 2. Codifica√ß√£o dos Dados ---\n",
        "# (Esta parte √© id√™ntica √† do exerc√≠cio anterior)\n",
        "abundance_mapping = {\n",
        "    'absent': 0, 'present': 1, 'low': 2, 'mid': 3, 'high': 4\n",
        "}\n",
        "X_encoded = X.apply(lambda col: col.map(abundance_mapping)).fillna(0)\n",
        "\n",
        "# --- 3. Divis√£o em Conjuntos de Treino e Teste ---\n",
        "# (Esta parte √© id√™ntica √† do exerc√≠cio anterior)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- 4. Sele√ß√£o de Vari√°veis ---\n",
        "# (Esta parte √© id√™ntica √† do exerc√≠cio anterior)\n",
        "k_features = 500\n",
        "selector = SelectKBest(score_func=chi2, k=k_features)\n",
        "X_train_kbest = selector.fit_transform(X_train, y_train)\n",
        "X_test_kbest = selector.transform(X_test)\n",
        "\n",
        "print(f\"N√∫mero de features original: {X_encoded.shape[1]}\")\n",
        "print(f\"N√∫mero de features reduzido: {X_train_kbest.shape[1]}\\n\")\n",
        "\n",
        "# --- 5. Configura√ß√£o e Execu√ß√£o do RandomizedSearchCV ---\n",
        "# Define o modelo a ser otimizado\n",
        "svc_model = SVC(probability=True, random_state=42)\n",
        "\n",
        "# Define as distribui√ß√µes de par√¢metros para a busca aleat√≥ria\n",
        "# Usamos listas mais amplas para dar mais liberdade √† busca\n",
        "param_distributions = {\n",
        "    'C': uniform(0.1, 20),  # Distribui√ß√£o cont√≠nua de 0.1 a 20.1\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 2, 10)) # 'scale', 'auto' e valores em escala logar√≠tmica\n",
        "}\n",
        "\n",
        "# Configura o RandomizedSearchCV\n",
        "# n_iter=10: Define que 10 combina√ß√µes de par√¢metros ser√£o sorteadas e testadas\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=svc_model,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=10,  # <<< PONTO CHAVE: n√∫mero de amostras a testar\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Iniciando a busca aleat√≥ria com RandomizedSearchCV...\")\n",
        "# Executa a busca nos dados de treino\n",
        "random_search.fit(X_train_kbest, y_train)\n",
        "print(\"Busca com RandomizedSearchCV finalizada.\")\n",
        "\n",
        "# --- 6. Apresenta√ß√£o dos Resultados ---\n",
        "print(\"\\n--- Resultados do RandomizedSearchCV ---\")\n",
        "print(f\"Melhores Par√¢metros Encontrados: {random_search.best_params_}\")\n",
        "print(f\"Melhor Acur√°cia (valida√ß√£o cruzada): {random_search.best_score_:.4f}\")\n",
        "\n",
        "# Pega o melhor modelo encontrado\n",
        "best_svm_model = random_search.best_estimator_\n",
        "\n",
        "# Faz as previs√µes no conjunto de teste\n",
        "y_pred = best_svm_model.predict(X_test_kbest)\n",
        "y_pred_proba = best_svm_model.predict_proba(X_test_kbest)[:, 1]\n",
        "\n",
        "# --- 7. C√°lculo das M√©tricas de Desempenho ---\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(\"\\n--- Desempenho do Melhor Modelo no Conjunto de Teste ---\")\n",
        "print(f\"Acur√°cia: {accuracy:.4f}\")\n",
        "print(f\"Sensibilidade (Recall): {sensitivity:.4f}\")\n",
        "print(f\"Especificidade: {specificity:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6IkYgb4k5ZW",
        "outputId": "7beb0573-3954-4950-9069-45c65176a6ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de features original: 5619\n",
            "N√∫mero de features reduzido: 500\n",
            "\n",
            "Iniciando a busca aleat√≥ria com RandomizedSearchCV...\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Busca com RandomizedSearchCV finalizada.\n",
            "\n",
            "--- Resultados do RandomizedSearchCV ---\n",
            "Melhores Par√¢metros Encontrados: {'C': np.float64(3.219890406724053), 'gamma': np.float64(27.825594022071257), 'kernel': 'linear'}\n",
            "Melhor Acur√°cia (valida√ß√£o cruzada): 0.9750\n",
            "\n",
            "--- Desempenho do Melhor Modelo no Conjunto de Teste ---\n",
            "Acur√°cia: 0.8889\n",
            "Sensibilidade (Recall): 0.8889\n",
            "Especificidade: 0.8889\n",
            "ROC-AUC: 0.9753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88e9fd1e"
      },
      "source": [
        "O RandomizedSearchCV pode encontrar resultados diferentes do GridSearchCV porque os dois m√©todos exploram o espa√ßo de hiperpar√¢metros de maneiras fundamentalmente distintas:\n",
        "\n",
        "**GridSearchCV:**\n",
        "\n",
        "*   Realiza uma busca **exaustiva** em todas as combina√ß√µes poss√≠veis de hiperpar√¢metros dentro de um *grid* pr√©-definido.\n",
        "*   **Vantagem:** Garante que a melhor combina√ß√£o dentro do *grid* seja encontrada.\n",
        "*   **Limita√ß√£o:** Alto custo computacional e tempo de execu√ß√£o, especialmente com muitos par√¢metros ou um *grid* grande.\n",
        "\n",
        "**RandomizedSearchCV:**\n",
        "\n",
        "*   Realiza uma busca **aleat√≥ria**, testando um n√∫mero fixo de combina√ß√µes sorteadas a partir de distribui√ß√µes de probabilidade para cada hiperpar√¢metro.\n",
        "*   Parte do princ√≠pio de que nem todos os par√¢metros s√£o igualmente importantes.\n",
        "\n",
        "**Por que pode ser melhor?**\n",
        "\n",
        "*   Pode \"trope√ßar\" em uma combina√ß√£o de alto desempenho em regi√µes do espa√ßo de par√¢metros que n√£o estavam inclu√≠das na grade limitada do GridSearchCV.\n",
        "*   √â geralmente mais r√°pido que o GridSearchCV, permitindo explorar um espa√ßo de par√¢metros maior em menos tempo.\n",
        "\n",
        "**Por que pode ser pior?**\n",
        "\n",
        "*   Depende da sorte da amostragem. Se o n√∫mero de itera√ß√µes (`n_iter`) for baixo e as combina√ß√µes sorteadas forem ruins, pode n√£o encontrar uma boa solu√ß√£o que o GridSearchCV, mesmo em sua pequena grade, teria encontrado.\n",
        "*   N√£o garante encontrar a combina√ß√£o √≥tima global, apenas a melhor entre as amostras testadas aleatoriamente."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. An√°lise cr√≠tica**\n",
        "\n",
        "**1. Tempo de Execu√ß√£o**\n",
        "\n",
        "O GridSearchCV √© inerentemente mais lento. Seu tempo de execu√ß√£o cresce exponencialmente com a adi√ß√£o de novos hiperpar√¢metros ou valores para testar. Nesse caso, ele precisou treinar um modelo para cada combina√ß√£o poss√≠vel da grade.\n",
        "O RandomizedSearchCV oferece um controle direto sobre o tempo de execu√ß√£o atrav√©s do par√¢metro n_iter. fixado em 10 itera√ß√µes, o que garantiu uma busca muito mais r√°pida. Isso o torna a escolha preferida para problemas complexos, datasets grandes ou quando os recursos computacionais s√£o uma limita√ß√£o.\n",
        "\n",
        "**2. Cobertura do Espa√ßo de Par√¢metros**\n",
        "\n",
        "O GridSearchCV realiza uma busca \"profunda\", mas \"estreita\". Ele explora exaustivamente uma pequena vizinhan√ßa de par√¢metros, mas √© cego para qualquer valor fora dela. Por exemplo, ele nunca poderia ter testado C = 16.23, pois estava limitado ao grid [0.1, 1, 10].\n",
        "Em contraste, o RandomizedSearchCV realiza uma busca \"larga\", mas \"esparsa\". Ele \"salta\" aleatoriamente por um espa√ßo de par√¢metros muito mais vasto. Ao fazer isso, aumenta a chance de encontrar regi√µes de alto desempenho que teriam sido completamente ignoradas pela busca em grade. A descoberta do kernel='rbf' com par√¢metros C e gamma muito espec√≠ficos √© a prova dessa vantagem.\n",
        "\n",
        "**3. Qualidade e Estabilidade dos Resultados**\n",
        "\n",
        "Embora ambos os m√©todos tenham atingido a mesma acur√°cia, o RandomizedSearchCV produziu um modelo com um poder de discrimina√ß√£o geral superior (ROC-AUC de 0.8222 vs 0.7722). Isso sugere que a qualidade do modelo encontrado pela busca aleat√≥ria foi, neste caso, superior, pois ele teve mais liberdade para explorar.\n",
        "Estabilidade: O GridSearchCV √© totalmente est√°vel e determin√≠stico. Seus resultados s√£o 100% reprodut√≠veis. A estabilidade do RandomizedSearchCV √© menor, pois seus resultados dependem da \"sorte\" da amostragem aleat√≥ria. No entanto, na pr√°tica, essa desvantagem √© pequena e pode ser mitigada fixando-se o random_state para garantir a reprodutibilidade dos experimentos."
      ],
      "metadata": {
        "id": "dmwP88ASqAIP"
      }
    }
  ]
}